{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carto2gpd\n",
    "import cenpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "import missingno as msno\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "import math \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['pa','il','ga','ca']\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://lehd.ces.census.gov/data/lodes/LODES7/pa/wac/pa_wac_S000_JT00_\"\n",
    "wac = dd.concat([pd.read_csv(gzip.open(BytesIO(urlopen(url+year+\".csv.gz\").read()))).assign(year=year) for year in years])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable description\n",
    "![Drag](WAX-data-description-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac['w_geocode'] = wac['w_geocode'].astype('str').str[:12]\n",
    "wac.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block group download link: https://www2.census.gov/geo/tiger/TIGER2019/BG/tl_2019_42_bg.zip\n",
    "phl_bg = gpd.read_file(\"tl_2019_42_bg/tl_2019_42_bg.shp\").query(\"COUNTYFP in ['017','029','045','091','101']\").to_crs('EPSG:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file and find the .shp file we need\n",
    "resp = urlopen(\"https://www2.census.gov/geo/tiger/TIGER2019/BG/tl_2019_42_bg.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "filenames = zipfile.namelist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_geo = phl_bg[['GEOID','geometry']].merge(wac.compute(), left_on='GEOID', right_on='w_geocode', how='inner')\n",
    "wac_all = wac_geo.groupby('GEOID')['C000'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all1 = pd.merge(wac_geo[[\"GEOID\",\"geometry\"]],wac_all,on=\"GEOID\",how=\"inner\")\n",
    "wac_all1 = wac_all1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all1[\"log_c000\"] = wac_all1[\"C000\"].apply(lambda x: math.log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all1.hvplot(geo=True,\n",
    "                c=\"log_c000\",\n",
    "                crs=3857,\n",
    "                hover_fill_color=\"gray\",\n",
    "                width=600, \n",
    "                height=400,\n",
    "                cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all1.hvplot(geo=True,\n",
    "                c=\"C000\",\n",
    "                crs=3857,\n",
    "                hover_fill_color=\"gray\",\n",
    "                width=600, \n",
    "                height=400,\n",
    "                cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2 = wac_all1[[\"C000\",\"GEOID\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler expects the features to be a 2D array with shape: (number of observations, number of features). \n",
    "# We are explicitly adding a second axis with the np.newaxis variable.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(wac_all2[\"C000\"][:, np.newaxis])\n",
    "\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method to find k\n",
    "\n",
    "# # Number of clusters to try out\n",
    "n_clusters = list(range(2, 10))\n",
    "\n",
    "# Run kmeans for each value of k\n",
    "inertias = []\n",
    "for k in n_clusters:\n",
    "    \n",
    "    # Initialize and run\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(scaled_features)\n",
    "    \n",
    "    # Save the \"inertia\"\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "# Plot it!\n",
    "plt.plot(n_clusters, inertias, marker='o', ms=10, mfc='white', lw=4, mew=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of clusters seems to be 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=8)\n",
    "\n",
    "# Run the fit!\n",
    "kmeans.fit(scaled_features)\n",
    "\n",
    "# Save the cluster labels\n",
    "wac_all2['label'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average features per cluster\n",
    "wac_all2.groupby('label', as_index=False).size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "wac_all2 = wac_all2.to_crs(epsg=3857)\n",
    "\n",
    "# setup the figure\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# plot, coloring by label column\n",
    "# specify categorical data and add legend\n",
    "wac_all2.plot(\n",
    "    column=\"label\",\n",
    "    cmap=\"Dark2\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    edgecolor=\"k\",\n",
    "    lw=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.axis(\"equal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2[\"label\"] = wac_all2[\"label\"].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2.hvplot(geo=True,\n",
    "                c=\"label\",\n",
    "                crs=3857,\n",
    "                hover_fill_color=\"gray\",\n",
    "                width=600, \n",
    "                height=400,\n",
    "                cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters to start with\n",
    "eps = 50  # in meters\n",
    "min_samples = 50\n",
    "\n",
    "cores, labels = dbscan(wac_all2[\"C000\"][:, np.newaxis], eps=eps, min_samples=min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2['label_dbscan'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = len(cores)\n",
    "print(f\"Number of core samples = {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of clusters is the number of unique labels minus one (because noise has a label of -1)\n",
    "\n",
    "num_clusters = wac_all2['label_dbscan'].nunique() - 1\n",
    "print(f\"number of clusters = {num_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = wac_all2.groupby('label_dbscan', as_index=False).size()\n",
    "\n",
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cluster = 4. Number of noise point is 1530."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "wac_all2 = wac_all2.to_crs(epsg=3857)\n",
    "\n",
    "# setup the figure\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# plot, coloring by label column\n",
    "# specify categorical data and add legend\n",
    "wac_all2.plot(\n",
    "    column=\"label_dbscan\",\n",
    "    cmap=\"Dark2\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    edgecolor=\"k\",\n",
    "    lw=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.axis(\"equal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2[\"label_dbscan\"] = wac_all2[\"label_dbscan\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all2.hvplot(geo=True,\n",
    "                c=\"label_dbscan\",\n",
    "                crs=3857,\n",
    "                hover_fill_color=\"gray\",\n",
    "                width=600, \n",
    "                height=400,\n",
    "                cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse more variables\n",
    "variables = ['GEOID', 'geometry', 'w_geocode', 'C000', 'CA01', 'CA02', 'CA03',\n",
    "       'CE01', 'CE02', 'CE03', 'CNS01', 'CNS02', 'CNS03', 'CNS04', 'CNS05',\n",
    "       'CNS06', 'CNS07', 'CNS08', 'CNS09', 'CNS10', 'CNS11', 'CNS12', 'CNS13',\n",
    "       'CNS14', 'CNS15', 'CNS16', 'CNS17', 'CNS18', 'CNS19', 'CNS20', 'CR01',\n",
    "       'CR02', 'CR03', 'CR04', 'CR05', 'CR07', 'CT01', 'CT02', 'CD01', 'CD02',\n",
    "       'CD03', 'CD04', 'CS01', 'CS02','year']\n",
    "wac_var = wac_geo[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method to find k\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(wac_var.drop(['year','GEOID','geometry'],axis=1))\n",
    "\n",
    "scaled_features\n",
    "# # Number of clusters to try out\n",
    "n_clusters = list(range(2, 10))\n",
    "\n",
    "# Run kmeans for each value of k\n",
    "inertias = []\n",
    "for k in n_clusters:\n",
    "    \n",
    "    # Initialize and run\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(scaled_features)\n",
    "    \n",
    "    # Save the \"inertia\"\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "# Plot it!\n",
    "plt.plot(n_clusters, inertias, marker='o', ms=10, mfc='white', lw=4, mew=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters to start with\n",
    "eps = 50  # in meters\n",
    "min_samples = 50\n",
    "\n",
    "cores, labels = dbscan(wac_var.drop(['year','GEOID','geometry'],axis=1), eps=eps, min_samples=min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_var['label_dbscan'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = wac_var.groupby('label_dbscan', as_index=False).size()\n",
    "\n",
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_var[\"label_dbscan\",'year','geometry'].hvplot(geo=True,\n",
    "                c=\"label_dbscan\",\n",
    "                crs=3857,\n",
    "                hover_fill_color=\"gray\",\n",
    "                width=1000, \n",
    "                height=850,\n",
    "                cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_var"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf3ea6aaf424934a07b160f87c7cf06fa269ee38c446bbd14a1e443e74b45d47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('musa-550-fall-2021': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
